<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="InstanceAnimator: Multi-Instance Sketch Video Colorization">
  <meta name="keywords" content="Sketch Colorization, Multi-Instance, Video Colorization">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>InstanceAnimator: Multi-Instance Sketch Video Colorization</title>

  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">InstanceAnimator: Multi-Instance Sketch Video Colorization</h1>
          <h1 class="title is-3"> arXiv 2025</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a> Yinhan Zhang</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a> Yue Ma </a><sup>2</sup>,</span>
            <span class="author-block">
              <a> Bingyuan Wang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a> Kunyu Feng</a><sup>1</sup>,</span> <br>
            <span class="author-block">
              <a> Qifeng Chen</a><sup>2</sup>,</span>
            <span class="author-block">
              <a> Anyi Rao</a><sup>2</sup>,</span>
            <span class="author-block">
              <a> Zeyu Wang</a><sup>1,2</sup>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>HKUST(GZ),</span>
            <span class="author-block"><sup>2</sup>HKUST</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://github.com/YinHan-Zhang/InstanceAnimator"
                   class="external-link button is-normal is-rounded is-dark">
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/YinHan-Zhang/InstanceAnimator"
                   class="external-link button is-normal is-rounded is-dark">
                  <span>Code</span>
                  </a>
                  <span class="link-block">
                    <a href="https://modelscope.cn/datasets/NiceYinHan/OpenAnimate"
                       class="external-link button is-normal is-rounded is-dark">
                      <span>Dataset</span>
                      </a>
                      </span>
                    
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<!-- Teaser. -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div>
        <img src="./static/images/teaser.png" alt="results" class="center">
        <br>
        <p>
          <b>Example results of InstanceAnimator.</b> Given diverse instances, sketch sequences, and textual descriptions, our framework
          enables high-quality, controllable video colorization with multi-instance and background customization
        </p>
      </div>
    </div>
  </div>
</section>



<!-- demo video -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Demo Video</h2>
          <video controls style="width:100%; max-width:1200px;">
            <source src="./static/images/video.mp4" type="video/mp4">
            您的浏览器不支持视频标签。
          </video>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container">

    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
      <div class="column is-full-width">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <img src="./static/images/introduction.png" alt="abstract" style="width:100%; ">
          <br>
          <p>
            <b>Motivation.</b> Unlike traditional methods that require multi-stage, frame-by-frame colorization, InstanceAnimator supports col-
            orizing sketch sequences into videos directly after background and character design. Our method no longer relys in single reference
            keyframe but adjusts instance-level colorization, providing higher user flexibility and significantly reducing time consumption and labor
            <br>
            <b>Overview.</b> Existing animation colorization methods rely heavily on a single initial reference frame, resulting in fragmented workflows and limited customizability.
            To eliminate these constraints, we introduce a Canvas Guidance Condition that allows users to freely place reference elements on a blank canvas, enabling flexible user control.
            To address the misalignment and quality degradation issues of DiT-based approaches, we design an Instance Matching Mechanism that integrates the instances with the sketch and noise channels, ensuring visual consistency across different sequences while maintaining controllability.
            Additionally, to mitigate the degradation of fine-grained instance and background details, we propose an Adaptive Decoupled Control Module that injects semantic features from characters, backgrounds, and text conditions into the diffusion model, significantly enhancing detail fidelity. 
          </p>
      </div>
    </div>

    <!-- Framework. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <br />
        <h2 class="title is-3">Framework</h2>
          <img src="./static/images/framework.png" alt="pipeline" style="width:100%; ">
        <div class="content has-text-justified">
          <br>
          <p>
            <b>Overview of InstanceAnimator.</b> We first fuse instance latent features with sketch and noise channels to establish a corre-
            spondence between the line drawing and the reference instance, as well as to maintain the character feature. Concurrently, instances,
            background, and text descriptions are fed into the Adaptive Decoupled Control Module independently, which dynamically injects condi-
            tion information into DiT blocks through three condition-specific expert modules. At the inference stage, users can adjust the conditional
            weights to enhance controllability and creative flexibility
          </p>
        </div>
      </div>
    </div>

     <!-- Test Protocol. -->
     <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <br />
        <h2 class="title is-3">Dataset</h2>
        <div class="content has-text-justified">
          <p>
            The current colorization datasets are generally based on reference frames and protect multiple scenes, which cannot meet the instance-level colorization task. Therefore, we constructed this dataset.
            This dataset is designed for the instance-aware sketch video colorization task and aimed at promoting the development of automatic animation techniques. This dataset includes two parts. One is a filter subset from the Sakuga42M dataset, the other is collected from animation films on the internet. The total video clips are about 40K+, and each video clip is in the same scene, which is cut by scene-cutting algorithms.  For each data clip, we provide a reference frame, multiple reference instances, a background image, and a text description.
          </p>
        </div>
          <img src="./static/images/data_pipeline.png" alt="pipeline" style="width:100%; ">
      </div>
    </div>

    <!-- Results. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <br />
        <h2 class="title is-3">More Results</h2>
        <div class="content has-text-justified">
          
        </div>
        <img src="./static/images/control.png" alt="face" style="width:100%; ">
        <div text-align:center>
          <p class="center">
            Given the same sketch and different reference instances, InstanceAnimator generates a variety of colorful videos.
          </p>
        </div>

        <br>

        <img src="./static/images/control2.png" alt="scene" style="width:100%; ">
        <div text-align:center>
          <p class="center">
            Using the same designed characters, our framework colorizes different sketches with consistent colors and user-customized backgrounds.
          </p>
        </div>

        <br>

        <img src="./static/images/bg_control2.png" alt="scene" style="width:100%; ">
        <div text-align:center>
          <p class="center">
            <b>Visual background control.</b> Our method supports customized visual background control in combination with reference instance and line drawing during the colorization process.
          </p>
        </div>

        <br>

        <img src="./static/images/style_control.png" alt="more_results" style="width:100%; "> 
        <div text-align:center>
          <p class="center">
            <b>Colorization from Different Style Reference.</b> For the same character, our method easily learn features. For different style characters, our method can transfer their style to the sketches even without prior knowledge.
          </p>
        </div>

        <br>

        <img src="./static/images/multi_ref.png" alt="more_results" style="width:100%; ">
        <div text-align:center>
          <p class="center">
            <b>Multiple Reference Instances Control.</b> While we obtain different style reference instances from the internet, our method can match the most similar character and follow the reference instance style to colorize the sketch sequence
          </p>
        </div>
        
      </div>
    </div>
  </div>
</section>




<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <div class="content has-text-justified">
      <p>
         If you find this paper helpful to your work, please cite our paper with the following BibTeX reference:
      </p>
    </div>
    <pre><code> ...
    </code></pre>
  </div>
</section>



</body>
</html>
